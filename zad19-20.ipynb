{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bf9ea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lower, explode, split, length, col, lit, log, array_contains, regexp_replace\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "101e0ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/18 14:39:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "STOP_WORDS_PATH = \"szekspir/stop_words_english.txt\"\n",
    "TEXTE_PATHS = [\n",
    "    \"szekspir/Hamlet.txt\",\n",
    "    \"szekspir/KingLear.txt\",\n",
    "    \"szekspir/Othello.txt\",\n",
    "    \"szekspir/RomeoJuliet.txt\",\n",
    "]\n",
    "HAMLET_TEXT_PATH = TEXTE_PATHS[0]\n",
    "\n",
    "spark = SparkSession.builder.appName(\"ShakespeareTextProcessing\").getOrCreate()\n",
    "\n",
    "stop_words = []\n",
    "with open(STOP_WORDS_PATH, 'r') as f:\n",
    "    for line in f:\n",
    "        stop_words.append(line.strip().lower())\n",
    "\n",
    "textes = {}\n",
    "for path in TEXTE_PATHS:\n",
    "    with open(path, 'r') as f:\n",
    "        textes[path] = f.read()\n",
    "\n",
    "hamlet_df = spark.createDataFrame([(textes[HAMLET_TEXT_PATH],)], [\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7db1efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(df, stop_words):\n",
    "    return df \\\n",
    "    .select(\n",
    "        col(\"doc_id\"),\n",
    "        lower(regexp_replace(col(\"text\"), \"[^a-zA-Z0-9\\\\s]\", \" \")).alias(\"cleaned_doc\")\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        \"word\", explode(split(col(\"cleaned_doc\"), \"\\\\s+\"))\n",
    "    ) \\\n",
    "    .filter(\n",
    "        (col(\"word\") != \"\") & \n",
    "        (~array_contains(lit(stop_words), col(\"word\"))) & \n",
    "        (length(col(\"word\")) > 2)\n",
    "    )\n",
    "\n",
    "def get_top_n_words(word_counts, n=20):\n",
    "    return word_counts.groupBy(\"word\").count().orderBy(col(\"count\").desc()).limit(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0c4626f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word counts in Hamlet:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|       word|count|\n",
      "+-----------+-----+\n",
      "|     hamlet|  480|\n",
      "|       lord|  226|\n",
      "|       king|  207|\n",
      "|    horatio|  161|\n",
      "|      queen|  123|\n",
      "|   polonius|  119|\n",
      "|    laertes|  111|\n",
      "|       good|  108|\n",
      "|    ophelia|   89|\n",
      "|        thy|   87|\n",
      "|        sir|   77|\n",
      "|rosencrantz|   75|\n",
      "|      enter|   73|\n",
      "|        tis|   73|\n",
      "|     father|   71|\n",
      "|       love|   69|\n",
      "|       hath|   65|\n",
      "|      speak|   64|\n",
      "|        man|   60|\n",
      "|       thee|   59|\n",
      "+-----------+-----+\n",
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x7f3039cdd010>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamlet_text = \"\"\n",
    "with open(HAMLET_TEXT_PATH, 'r') as f:\n",
    "    hamlet_text = f.read()\n",
    "hamlet_df = spark.createDataFrame([(hamlet_text,)], [\"text\"])\n",
    "\n",
    "hamlet_word_counts = count_words(hamlet_df.withColumn(\"doc_id\", lit(1)), stop_words)\n",
    "print(\"Word counts in Hamlet:\")\n",
    "print(get_top_n_words(hamlet_word_counts, n=20).show())\n",
    "\n",
    "wordCloud = WordCloud(width=800, height=400, background_color='white')\n",
    "wordCloud.generate_from_frequencies(\n",
    "    {row['word']: row['count'] for row in get_top_n_words(hamlet_word_counts, n=100).collect()}\n",
    ")\n",
    "wordCloud.to_file(\"wordcloud_Hamlet.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "363fd6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tf_idf(dfs, stop_words):\n",
    "    if dfs.count() == 0:\n",
    "        return spark.createDataFrame([], [\"word\", \"tf_idf\"])\n",
    "    \n",
    "    word_counts_list = count_words(dfs, stop_words)\n",
    "    word_frequencies = word_counts_list.groupBy(\"doc_id\", \"word\").count().withColumnRenamed(\"count\", \"term_count\")\n",
    "    doc_lengths = word_counts_list.groupBy(\"doc_id\").count().withColumnRenamed(\"count\", \"doc_length\")\n",
    "\n",
    "    tf = word_frequencies.join(doc_lengths, \"doc_id\") \\\n",
    "        .withColumn(\"tf\", col(\"term_count\") / col(\"doc_length\")) \\\n",
    "        .select(\"doc_id\", \"word\", \"tf\")\n",
    "    \n",
    "    frequency = word_frequencies.select(\"word\", \"doc_id\").distinct() \\\n",
    "        .groupBy(\"word\").count().withColumnRenamed(\"count\", \"doc_frequency\")\n",
    "    \n",
    "    idf = frequency.withColumn(\"idf\", \n",
    "        log(lit(dfs.select(\"doc_id\").distinct().count()) / col(\"doc_frequency\"))\n",
    "    ).select(\"word\", \"idf\") \n",
    "\n",
    "    tf_idf = tf.join(idf, \"word\") \\\n",
    "        .withColumn(\"tf_idf\", col(\"tf\") * col(\"idf\")) \\\n",
    "        .select(\"doc_id\", \"word\", \"tf_idf\")\n",
    "    \n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19fde271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+--------------------+\n",
      "|     doc_id|     word|              tf_idf|\n",
      "+-----------+---------+--------------------+\n",
      "|     Hamlet|   hamlet|0.053353214667859805|\n",
      "|    Othello|     iago|0.046850052833203565|\n",
      "|    Othello|  othello| 0.04347581080089527|\n",
      "|    Othello|   cassio|0.032963749084857906|\n",
      "|    Othello|desdemona|0.029459728512845455|\n",
      "|   KingLear|     lear|0.027721128230426925|\n",
      "|   KingLear|     kent|0.020701615073366028|\n",
      "|RomeoJuliet|      rom| 0.02064181792843173|\n",
      "|RomeoJuliet|    romeo|0.019755359489787423|\n",
      "|     Hamlet|  horatio|0.017895557419844645|\n",
      "|    Othello|   emilia|0.017779659939470605|\n",
      "|   KingLear|     glou|0.014039026314121789|\n",
      "|    Othello| roderigo|0.013626746668937326|\n",
      "|     Hamlet| polonius| 0.01322715113640691|\n",
      "|     Hamlet|  laertes| 0.01233793089194258|\n",
      "|RomeoJuliet|    friar|0.011777233541988657|\n",
      "|   KingLear|      edg| 0.01165953032867742|\n",
      "|     Hamlet|  ophelia|0.009892575219665672|\n",
      "|RomeoJuliet|    nurse|0.009497768985474723|\n",
      "|   KingLear|      edm|0.009399009142505264|\n",
      "+-----------+---------+--------------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_data = [(doc_path.split('/')[-1].replace('.txt', ''), text_content)  for doc_path, text_content in textes.items()]\n",
    "dfs = spark.createDataFrame(df_data, [\"doc_id\", \"text\"])\n",
    "tf_idf_scores = calculate_tf_idf(dfs, stop_words)\n",
    "\n",
    "print(tf_idf_scores.orderBy(col(\"tf_idf\").desc()).limit(20).show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab4c571f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for doc_id in dfs.select(\"doc_id\").distinct().collect():\n",
    "    doc_tf_idf = tf_idf_scores.filter(col(\"doc_id\") == doc_id['doc_id'])\n",
    "    wordCloud = WordCloud(width=800, height=400, background_color='white')\n",
    "    wordCloud.generate_from_frequencies(\n",
    "        {row['word']: row['tf_idf'] for row in doc_tf_idf.collect()}\n",
    "    )\n",
    "    wordCloud.to_file(f\"wordcloud_tf_idf_{doc_id['doc_id']}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
